# W4 Project - ETL NFL Penalties

![portada](https://github.com/CharlyKill7/Database-Project/blob/main/images/videoclub.jpg)

## ndice

1. [Descripci贸n](#descripci贸n)
2. [Extracci贸n](#extracci贸n)
3. [Transformaci贸n](#transformaci贸n)
4. [Carga](#carga)
5. [BONUS: Consultas y conclusi贸n](#consultas)


<a name="descripci贸n"/>

## Descripci贸n del proyecto

En este proyecto habremos de efectuar un proceso completo de ETL, las siglas en ingl茅s de Extract, Transform y Load. Los datos a extraer ser谩n de nuestra elecci贸n, pero habr谩 que cumplir ciertos requerimientos. En este caso, vamos a extraer datos y hacer un peque帽o an谩lisis acerca de las decisiones arbitrales en la NFL.

### Restricciones:
- Obtener la informaci贸n de tres fuentes distintas (urls).
- Dos m茅todos distintos de extracci贸n (csv, excel, api, rss, web scrapping...).

### Objetivo:
 
Nuestro objetivo es encontrar tres fuentes de datos distintas sobre las se帽alizaciones arbitrales en la NFL, de tal modo que podamos generar un DataFrame rico y completo a trav茅s del cual podamos sacar conclusiones al respecto. En este sentido, trabajaremos en la transformaci贸n del dato crudo para su adaptaci贸n al resto de las fuentes, con el fin de establecer una base de datos SQL con los resultados, pudiendo lanzar queries que nos ayuden a confirmar o refutar las hip贸tesis que planteemos.

 
 <a name="extracci贸n"/>
 
## Extracci贸n

En primer lugar, hemos realizado un ejercicio anal铆tico de numerosas p谩ginas web, incluyendo Kaggle o Google Dataset Search. Al no encontrar ning煤n dataset que se ajustara al objetivo, ampliamos la b煤squeda a cualquier url que pudiera proporcionar la informaci贸n requerida. Durante este proceso, encontramos las siguientes tablas:

<details>
<summary>https://www.nflpenalties.com/</summary>
<br>

 ![nflpenalties](https://github.com/CharlyKill7/Database-Project/blob/main/images/Susandavis.png)

</details>

<details>
<summary>https://www.pro-football-reference.com/</summary>
<br>

 ![profootballreference](https://github.com/CharlyKill7/Database-Project/blob/main/images/Susandavis.png)

</details>

<details>
<summary>https://www.profootballnetwork.com/</summary>
<br>

 ![profootballnetwork](https://github.com/CharlyKill7/Database-Project/blob/main/images/Susandavis.png)

</details>



**Proceso de extracci贸n**

Para la primera url, el proceso de extracci贸n consisti贸 en hacer web scrapping, utilizando la librer铆a selenium. Tras conseguir tanto los nombres de columna como los datos, mediante la librer铆a pandas generamos nuestro DataFrame principal. A partir de este, la idea fue extraer datos que pudieran complementar los ya existentes.

Como en la primera url conseguimos los datos de "Penalties" de la primera jornada, decidimos completar esa tabla con una columna que devolviera al ganador del partido en cuesti贸n, de modo que pudieramos comprobar la incidencia arbitral en el 茅xito deportivo. Para ello descargamos un archivo boxscore en formato xlsx con el ganador y perdedor del partido en cuesti贸n, entre otros datos. 

Finalmente decidimos comprobar la incidencia del horario en las decisiones arbitrales, pues existe una creencia popular que asocia los partidos de "prime time" con un n煤mero mayor de se帽alizaciones, ya que los colegiados aparecen m谩s en pantalla cuando se televisa a todo el pa铆s. Para ello extraimos un archivo .csv con el "schedule" de la primera jornada.



 <a name="transformaci贸n"/>
 
## Transformaci贸n

El proceso de transformaci贸n por cada tabla fue el siguiente:

- En la primera url obtuvimos un primer DataFrame gracias al web scrapping y la librer铆a Selenium. Una vez obtenido el DF, optamos por mantenerlo intacto hasta despu茅s de conectarlo con la informaci贸n de las otras dos url. Finalmente, una vez enriquecida esta nuestra tabla principal, decidimos eliminar unas cuantas columnas cuya informaci贸n, aunque interesante, no parec铆a valiosa para nuestro objetivo ("Player", "Declined", "Offsetting"...). Tambi茅n rellenamos algunos de los valores vac铆os de la columna 'Pos' con NP (No position). La columna 'Time', con los minutos y segundos restantes de partido la tranformamos en segundos y la llamamos 'Time left'. Finalmente ajustamos el tipo de dato para optimizar el Dataframe.

<br>

<img src="https://github.com/CharlyKill7/Database-Project/blob/main/images/EERD_inicial.png" width="550" height="400" />


- En la segunda url conseguimos un archivo xlsx, que tambi茅n convertimos a DataFrame. Al no tener un 铆ndice, decidimos a帽adirlo. Despu茅s, como s贸lo necesitabamos la informaci贸n de la primera jornada, eliminamos todas las filas correspondientes a otras fechas del campeonato. A continuaci贸n tomamos una decisi贸n que afect贸 a todos nuestros DFs: unificar los nombres de los equipos bajo las siglas habituales (BAL, BUF, KC, NYG...), lo cual logramos mediante diccionarios con los cambios y la funci贸n .map. Una vez unificamos los nombres, a帽adimos dos columnas ('Winner' y 'Loser') al DF principal. 

<br>

<img src="https://github.com/CharlyKill7/Database-Project/blob/main/images/EERD_inicial.png" width="550" height="400" />


- En la tercera url descargamos un archivo csv con el los horarios por jornada de los partidos, que tambi茅n convertimos a DataFrame. Entonces aplicamos alguns m茅todos b谩sicos de la librer铆a Pandas para renombrar las columnas, eliminar duplicados, valores nulos y columnas sin inter茅s, adem谩s de unificar los nombres como para el DF anterior. Finalmente, generamos una columna extra 'Prime Time' (YES/NO) para cada partido, la cual a帽adimos al DF principal para obtener nuestra tabla final.

<br>

<img src="https://github.com/CharlyKill7/Database-Project/blob/main/images/EERD_inicial.png" width="550" height="400" />

<a name="carga"/>

## Carga

Una vez finalizada la transformaci贸n de los datos, obtuvimos un 煤nico DataFrame que exportar a MySQL. Para ello, creamos la base de datos "nflpenalties" y dise帽amos su EERD correspondiente. Tras un hacer Forward Engineer creamos la tabla "penalties_week_1_2022", en un principio vac铆a. Despu茅s, mediante SQLAlchemy realizamos la exportaci贸n y rellenamos dicha tabla, finalizando as铆 el proceso de carga. 

<br>

![penalties_week_1_2022](https://github.com/CharlyKill7/Database-Project/blob/main/images/inventory_master.png)

</details>


<a name="consultas"/>

##  BONUS: Consultas y conclusi贸n

<details>
<summary>LOS CLIENTES QUE MS ALQUILAN</summary>
<br>

 ```
SELECT  rental.customer_id, count(rental.customer_id) as Rentals
FROM rental
 
LEFT JOIN customer ON rental.customer_id = customer.customer_id
 
GROUP BY rental.customer_id
 
ORDER BY Rentals desc
LIMIT 5
 ```

![top_clientes_cantidad](https://github.com/CharlyKill7/Database-Project/blob/main/images/top_clientes_cantidad.PNG)
	
</details>

<details>
<summary>LOS CLIENTES QUE MS GASTAN</summary>
<br>

```
SELECT  `customer id`, round(sum(Income),2) as 'Total Spent'
FROM rental_master
 
GROUP BY `customer id`
 
ORDER BY 'Total Spent' desc
LIMIT 5 
 ```

![top_clientes_income2](https://github.com/CharlyKill7/Database-Project/blob/main/images/top_clientes_income2.PNG)

</details>

<details>
<summary>LAS PELCULAS QUE MS SE ALQUILAN</summary>
<br>

```
SELECT  title, count(title) as Alquileres
FROM rental_master
 
GROUP BY title
 
ORDER BY Alquileres DESC
LIMIT 5
 ```

![top_pelis](https://github.com/CharlyKill7/Database-Project/blob/main/images/top_pelis.png)

</details>
